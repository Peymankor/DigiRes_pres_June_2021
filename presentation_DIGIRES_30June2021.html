<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>BayesOpt Presentation</title>
    <meta charset="utf-8" />
    <meta name="author" content="Peyman Kor" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/sfah.css" type="text/css" />
    <link rel="stylesheet" href="css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




&lt;!-- &lt;div class="my-footer"&gt;&lt;span&gt;arm.rbind.io/slides/xaringan&lt;/span&gt;&lt;/div&gt; --&gt;

&lt;!-- this adds the link footer to all slides, depends on my-footer class in css--&gt;
---
name: xaringan-title
class: center, top
background-image: url(test2.jpg)
background-size: cover

# BayesOpt : A New Sample Efficient Workflow for Reservoir Optimization under Uncertainty

&lt;!-- #&lt;img src="https://user-images.githubusercontent.com/163582/45438104-ea200600-b67b-11e8-80fa-d9f2a99a03b0.png" alt="Sharingan" width="180" /&gt; --&gt;

&lt;!-- ### .fancy[Making slides in R Markdown] --&gt;

&lt;br&gt;
&lt;br&gt;
### .large[Peyman Kor | Energy Resource Department, University of Stavanger]
### .large[Presentation for DigiRes Meeting, 30 June 2021]
&lt;!-- this ends up being the title slide since seal = FALSE--&gt;
---

---
name: sfah
class: top, top

## Introduction: Peyman Kor
.left-column[

&lt;img src="img/profile.jpg" width="600px" height="400px" style="display: block; margin: auto;" /&gt;

]
--
.right-column[

 * üá≥üá¥ PhD Student in Computational Engineering, University of Stavanger, Dec 2020 - Ongoing

  - Proxy-based Workflow for Reservoir Optimization under Uncertainty (DigiRes project)
  - Sequential Decision Making/Reinforcement Learning/ Stochastic Optimization
  - Supervisors: Reidar B. Bratvold and Aojie Hong

{{content}}
]
--

 * üá©üá∞ M.Sc in Applied Mathematics and Computation, Technical University of Denmark (2019 - 2020)
 
 &lt;!-- - Bayesian Neural Network for Probabilistic Forecasting --&gt;

{{content}}
--

 * üá≥üá¥ M.Sc in Reservoir Engineering, University of Stavanger (2017-2019)
 &lt;!-- - Development of XGBOOST model as Proxy Model for Numerical Rservoir Simulator --&gt;

{{content}}
--

 * üáÆüá∑ B.Sc in Petroleum Engineering , Petroleum University of Technology (2011-2016), IRAN
 &lt;!-- - Asphaletene Deposition Modeling along Wellbore --&gt;

{{content}}

---
class: center, top
## Today Presentation:

&lt;br/&gt;

--
### Part I) Problem Statement

--

### Part II) Workflow of Bayesian Optimization and Illustation

--

### Part III) Demonstarte the BayesOpt Application to Reservoir Optimization 

--

---

class: center, middle
## Part I) Problem Statement

---
## Part I) Problem Statemnet:

--
- In reservoir optimization, we can have different objectives: Recovery Factor, Net Present Value (NPV), ...

`$$u_M = \underset{u \in \text{constraints}}{\mathrm{argmax}}\, \text{Objective Func(u)}$$`
 `\(u\)` is a decision variable to make: could be injection rate, well locations, order of drilling wells.
--
 `$$\color{blue} {\text{Deterministic Optimization}}:\quad \text{Objective Func(u)}=J(u,G)=\sum_{k=1}^{n_T} \frac{q_o^k(u, G)P_o-q^k_w(u,G)P_{wp}-I^k(u,G)P_{wi}}{(1+b)^{t_k/D}}$$`
--

`$$\color{blue} {\text{Robust Optimization}} \qquad \qquad \text{Objective Func(u)}= \overline{J}(u) = \frac{\sum_{i=1}^{n_e} J_r(u,G_i)}{n_e}$$`
--
---
## Part I) Problem Statement

`$$\color{blue} {\text{Robust Optimization}} \qquad \qquad \text{Objective Func(u)}= \overline{J}(u) = \frac{\sum_{i=1}^{n_e} J_r(u,G_i)}{n_e}$$`

--

#### Example case: 

- Lets' say you are optimizng the well control problem with dimension, `\(d=10\)`

--

- Number of 3D geological realizations is `\(n_e=100\)` and running each possible `\(u^*\)`in commercial reservoir simulator, at each realization talks ~ 1 hour. Then time it takes to calculate `\(\overline{J}(u^*)\)` is ~ 100 hours.

--

- With 6 month CPU running time budget, the total available budget is to run is ~ 50.

--

- Availablity of only 50 `\(\overline{J}(u^*)\)` evaluation is a small budget, considering the 10 dimentional optimization problem.

--

#### **&lt;span style="color:red"&gt; Problem:&lt;/span&gt;**&lt;span style="color:red"&gt;  `\(\overline{J}(u)\)` is expensive function, meaning the # times we can evaluate it severely limited. &lt;/span&gt;

--

#### **&lt;span style="color:green"&gt; Solution:&lt;/span&gt;**&lt;span style="color:green"&gt;  Bayesian Optimization (BayesOpt) propose a new workflow to conduct optimization at the small `\(\overline{J}(u)\)` budget, without affecting the optimum solution.

---

## Expensive objective functions, who doesn‚Äôt have one?

--

*Parameter tuning in ML algorithms.*
--

&lt;img src="img/deeplearning.png" width="500px" height="300px" style="display: block; margin: auto;" /&gt;

--

- Number of layers/units per layer
- learning rates, etc.

--

---
## Expensive objective functions, who doesn‚Äôt have one?

--

*Active Path Finding*

--

&lt;img src="img/activepath.png" width="500px" height="300px" style="display: block; margin: auto;" /&gt;
--
&lt;br&gt;
- Optimise the location of a sequence of waypoints in a map to navigate from a location to a destination.

---
## Expensive objective functions, who doesn‚Äôt have one?
--

- Robotics, control, reinforcement learning.
- Compilers, hardware, software.
- Industrial design.

--

&lt;img src="img/egg.gif" width="900px" height="400px" style="display: block; margin: auto;" /&gt;

&lt;!-- ![time series](egg.gif){} --&gt;

---

class: center, middle
## Part II) Workflow of Bayesian Optimization and Illustation

---
## Part II) Workflow of Bayesian Optimization and Illustation
### Bayesian Optimization - Overall Idea

Workflow to perform global optimization of multimodal black-box functions:
--

####Step 1. Choose some initial design points and build a  &lt;span style="color:red"&gt;probabilistic model&lt;/span&gt; over the space of objective `\(\overline{J}(u)\)`, 
&lt;!-- this probabilistic model &lt;span style="color:red"&gt;serves as prior&lt;/span&gt;.  --&gt;
{{content}}

--

####Step 2. Combine step1. and the observationsto get a &lt;span style="color:red"&gt;posterior of probabilistic model&lt;/span&gt; 
{{content}}

--

####Step 3. Use the posterior to &lt;span style="color:red"&gt;decide&lt;/span&gt; where to take the next evaluation `\(\bf{u^*}\)` according to some &lt;span style="color:red"&gt;policy &lt;/span&gt;.
{{content}}
--

####Step 4. Evaluet the `\(\overline{J}(u)\)` at `\(\bf{u^*}\)` and &lt;span style="color:red"&gt;augment it to the initial data&lt;/span&gt;, in step 1.
{{content}}
--

Iterate between 2 and 4 until the evaluation budget is over.
---

## Step 1,2: Gaussian Process (GP) as Probalistic Model

Ref: (Kevin P. Murphy, Probabilistic Machine Learning: An introduction, 2021- Ch17)
{{content}}
--
- Key Assumption in (GP) is that: the function values at a set of `\(M &gt; 0\)` inputs, `\(\bf{\overline{J}(u)} = [\overline{J}(u_1), ...,\overline{J}(u_M)]\)`, is jointly Gaussian, with mean `\((\mu = m(u_1),...m(u_M))\)` and 
{{content}}
--
- Covariance `\(\sum_{i,j}= \Large \kappa(u_i,u_j)\)` , and `\(\Large \kappa\)` is a positive definite (Mercer) kernel.
{{content}}
--
`$$\begin{bmatrix}  {\bf {\overline{J}}_U}  \\  {{\bf \overline{J}}_*} \end{bmatrix} \sim\mathcal{N} \begin{pmatrix} (\begin{bmatrix}  {{\bf \mu}_U}  \\  {{\bf \mu}_*} \end{bmatrix}),\begin{bmatrix} {{\bf K}_{U,U}}  &amp; {{\bf
K}_{U,*}}  \\  {{\bf \mathbf{K}^\intercal}_{U,*}} &amp; {{\bf K}_{*,*} } \end{bmatrix}\end{pmatrix}$$`
--
`$$p(\overline{J}_*|U_*,\mathcal{D}) = \mathcal{N}(\overline{J}_*|{{\bf \mu}_*} , \scriptsize{\sum}_{*}\normalsize)=$$`
`$${{\bf \mu}_*}=m(\bf U_*) +{\bf \mathbf{K}^\intercal}_{U,*}{\bf \mathbf{K}^{-1}}_{U,U}(\overline{J}_U-m(U))$$`
`$$\scriptsize{\sum}_{*}= \normalsize{\mathbf{K}_{*,*}-\mathbf{K}^\intercal_{U,*}\mathbf{K}_{U,U}^{-1}\mathbf{K}_{U,*}}$$`
--
---
## Example of Step.1 and Step.2



.pull-left[
- Assume `\(U=[0,3,5,6]\)` and `\(\overline{J}(u)=sin(u)\)`, giving `\(\mathcal{D}=(U,\overline{J}(U))\)`. What is `\(p(\overline{J}_*|U_*,\mathcal{D})\)`?
{{content}}
]
--
&lt;img src="presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-6-1.png" width="504" /&gt;
--

.pull-right[
- Now we sample the point `\(u=1\)`, and add to `\(\mathcal{D}\)`
{{content}}
]
--
&lt;img src="presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-7-1.png" width="504" /&gt;
--
---
## Step.3 Deciding on next `\(\bf{u}^{next}\)` based on Posterior

{{content}}

--
- Posterior of the probalistic model  quantify the uncertainty over the space of the `\(\overline{J}(u)\)`. The question is what is the next `\(\bf{u}^{next}\)` to be sampled from the *expensive function*?

{{content}}
--
- Collect a new data point satisfying some optimality criterion: optimization as decision making.
{{content}}
--
&lt;!-- - There are a few of policies in the literature of Bayesopt, here the *Expected Improvement (EI)* policy will be used. --&gt;

&lt;!-- --- --&gt;

&lt;!-- ## Step.3 Deciding on next `\(\bf{x}^*\)` based on Posterior --&gt;
&lt;!-- ### Expected Improvement as Policy for Decision Making --&gt;

&lt;!-- - In Expected Improvement (EI) policy: &lt;span style="color:red"&gt; choose the next query point as the one which has the highest expected improvement over the space of the *expensive function*, f.&lt;/span&gt;   --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- `$$utility(x;\theta,\mathcal{D})=\alpha_{EI}=\int_{y}^{}max(0,y-f)p(y|x;\theta,\mathcal{D}) \,dy$$` --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- - However, we do not have access to the *expensive function*, `\(f\)`, therefore we replace the `\(f\)` with the best available solution found so far, `\(y^+\)` --&gt;
&lt;!-- - `$$utility(x;\theta,\mathcal{D})=\alpha_{EI}=\int_{y}^{}max(0,y-y‚Å∫)p(y|x;\theta,\mathcal{D}) \,dy$$` --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- - `\(y^+\)` : The best solution found in the training dataset `\(\mathcal{D}\)` --&gt;
&lt;!-- -- --&gt;
&lt;!-- --- --&gt;
&lt;!-- ## Step.3 Deciding on next `\(\bf{x}^*\)` based on Posterior --&gt;
&lt;!-- ### Expected Improvement as Policy for Decision Making (cont) --&gt;
&lt;!-- - The good news: The analytical form of the utility function is available for the gaussian process --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;

&lt;!-- - `$$\gamma(\mathbf{x})=\frac{\mu(\mathbf{x;\theta,\mathcal{D}})-y^+}{\sigma(\mathbf{x;\theta,\mathcal{D}})}$$` --&gt;
&lt;!-- - `$$utility(\mathbf{x};\theta,\mathcal{D})=\alpha_{EI}(x;\theta,\mathcal{D})=(\mu(x;\theta,\mathcal{D})-y^+)\Phi(\gamma(x)) + \sigma(x;\theta,\mathcal{D})\phi(\gamma(x))$$` --&gt;
&lt;!-- - Where `\(\Phi(.)\)` and `\(\phi(.)\)` are CDF and PDF of standard Gaussian distribution.  --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- - It is too greedy in the context of the sequential decision making. Therefore, an explorative term is added as  &lt;span style="color:red"&gt;"explorative" parameter `\(\epsilon\)` &lt;/span&gt;. --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;

`$$\gamma(\mathbf{u})=\frac{\mu(\mathbf{u;\theta,\mathcal{D}})-\overline{J}^+-\epsilon}{\sigma(\mathbf{u;\theta,\mathcal{D}})}$$`
`$$\alpha_{EI}(u;\theta,\mathcal{D})=(\mu(u;\theta,\mathcal{D})-\overline{J}^+-\epsilon)\Phi(\gamma(u)) + \sigma(u;\theta,\mathcal{D})\phi(\gamma(u))$$`
- `\(\mu(\mathbf{u;\theta,\mathcal{D}})\)`: mean value of the posterior model at point `\(u\)`, 
- `\(\sigma (\mathbf{u;\theta,\mathcal{D}})\)`: sd value of the posterior model at point `\(u\)`. 
- `\(\overline{J}^+\)`: the best `\(\overline{J}(u)\)` in the design points, `\(\mathcal{D}\)`.

{{content}}

--

`$$\color{red}{u^{next} = \underset{u}{\mathrm{argmax}} \;\; \alpha_{EI}(u;\theta,\mathcal{D})}$$`
--
---
## Example: Illustration of Bayesian Optimization
{{content}}
--

- We want to find the maximum of the *Ground Truth* function, in purple color. 
&lt;br/&gt;
&lt;br/&gt;
Iteration: 0

&lt;img src="img/gold_it0.png" width="700px" height="400px" style="display: block; margin: auto;" /&gt;
---
## Example: Illustration of Bayesian Optimization
{{content}}
--

- We want to find the maximum of the *Ground Truth* function, in purple color. 
&lt;br/&gt;
&lt;br/&gt;
- Iteration: 1

&lt;img src="img/gold_it1.png" width="700px" height="400px" style="display: block; margin: auto;" /&gt;
---

## Example: Illustration of Bayesian Optimization
{{content}}
--

- We want to find the maximum of the *Ground Truth* function, in purple color. 
&lt;br/&gt;
&lt;br/&gt;
- Iteration: 2

&lt;img src="img/gold_it2.png" width="700px" height="400px" style="display: block; margin: auto;" /&gt;
---

## Example: Illustration of Bayesian Optimization
{{content}}
--

- We want to find the maximum of the *Ground Truth* function, in purple color. 
&lt;br/&gt;
&lt;br/&gt;
- Iteration: 3

&lt;img src="img/gold_it3.png" width="700px" height="400px" style="display: block; margin: auto;" /&gt;
---
## Bayesian Optimization:
### As a "mapping" between two problems

- BO is an strategy to transform the problem

`$$u_M = \underset{u \; \in \; constraints}{\mathrm{argmax}}\, \overline{J}(u)$$`
{{content}}
--
`$$\color{red} {unsolvabale!}$$`
{{content}}
--
- `$$u^{next}=\underset{u \; \in \; constraints}{\mathrm{argmax}}\, \alpha_{EI}(u;\mathcal{D}_n, \theta^*)$$`
{{content}}
--

`$$\color{green} {solvabale!}$$`
{{content}}
--
- `\(\alpha_{EI}(u)\)` is inexpensive to evaluate.
- The analytical expression for gradient of `\(\alpha_{EI}(u)\)` is available.
- Still need to find `\(u^{next}\)`, the multi-start BFGS is used for finding `\(u^{next}\)`.


---
## BayesOpt Applied to Reservoir Case:

--
Egg Model (8 Injection wells, 4 Production wells)

.pull-left[
- Egg Model &lt;font size="3"&gt; (Jansen, J. D., et al (2014). The egg model‚Äìa geological ensemble for reservoir simulation. Geoscience Data Journal, 1(2), 192-195)&lt;/font&gt;

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/egg_base.jpg" alt="Well locations in Egg model, channalized reservoir" width="600px" height="300px" /&gt;
&lt;p class="caption"&gt;Well locations in Egg model, channalized reservoir&lt;/p&gt;
&lt;/div&gt;
]


--

.pull-right[

- Rel Perm Curves

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/egg_info.jpg" alt="Relative permeabilities and, associated fractional flow curve" width="400px" height="300px" /&gt;
&lt;p class="caption"&gt;Relative permeabilities and, associated fractional flow curve&lt;/p&gt;
&lt;/div&gt;

]

---

## BayesOpt Applied to Reservoir Case:
### Optimization Objective

--
- `$$J(u)= NPV(u)=\sum_{k=1}^{n_T} \frac{q_o^k(u)P_o-q^k_w(u)P_{wp}-I^k(u)P_{wi}}{(1+b)^{t_k/D}}$$`
- $$ \overline{J}(u) = \frac{\sum_{r=1}^{n_e} J_r(u)}{n_e} $$
--

.pull-left[
+ `\(u\)` is Injection rate for the each injection well, 
+ `\(u=[u_{inj1},u_{inj2},u_{inj3},u_{inj4},u_{inj5},u_{inj6},u_{inj7},u_{inj8}]^{\intercal}\)`
&lt;br/&gt;
&lt;br/&gt;
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Item &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Price in ($/m3) &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Items &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; `\(P_o\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 315 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; b &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 8% &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; `\(P_{wp}\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 47.5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; D &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 365 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; `\(P_{wi}\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 12.5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(n_e\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]
--

.pull-right[

&lt;img src="img/egg_amine.jpg" width="500px" height="200px" style="display: block; margin: auto 0 auto auto;" /&gt;

]
--
---

## BayesOpt Applied to Reservoir Case:

--
- Constrain on the Injection Rates, can be adjusted from `\(5m^3/day\)` to `\(100m^3/day\)`. 
- Initial reservoir pressure at the first layer is 400 bars, and producers are under minimal BHP of 395 bars.
- Latin hyper cube sampling (LHS) was conducted for initial design to calculate the `\(\mathcal{D}\)`: 
--

&lt;img src="presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-16-1.png" width="864" style="display: block; margin: auto;" /&gt;

```r
TeX('$\\gamma^\\alpha$')
```

```
## expression(`$\gamma^\alpha$` = paste("", "", gamma, , , , phantom()^{
##     paste(alpha, , , , "")
## }))
```



---
## BayesOpt Applied to Reservoir Case:

.pull-left[
- Blue Points represents initial design, Red points shows BayesOpt Sampling.
&lt;br/&gt;
&lt;br/&gt;
![](presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;

]
--
.pull-right[
- Maximum Value after Optimization of the the Utility Function `\(\alpha(x;\mathcal{D},\theta)\)`, (multi-start (1000)- L-BFGS-B) 
&lt;br/&gt;
![](presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

]
--
---

## BayesOpt Applied to Reservoir Case:

--
- Repeat the Optimization, three times, in different initial design points
--
-
![](presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-21-1.png)&lt;!-- --&gt;
--
---

## BayesOpt Applied to Reservoir Case:

--
-  Final Solution `\(u\)`, in three different initial design:
--

&lt;img src="presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-22-1.png" width="1008" style="display: block; margin: auto;" /&gt;



--
---
## BayesOpt Applied to Reservoir Case:
### BayesOpt VS. with other Global Optimization Algorithms

--

#### Particle Swarm Optimization (PSO)

- de Brito, D. U., &amp; Durlofsky, L. J. (2021). Field development optimization using a sequence of surrogate treatments. Computational Geosciences, 25(1), 35-65.

- Jesmani, M., Bellout, M. C., Hanea, R., &amp; Foss, B. (2016). Well placement optimization subject to realistic field development constraints. Computational Geosciences, 20(6), 1185-1209.

--
#### Genetic Algorithm Optimization (GA)

- Chai, Z., Nwachukwu, A., Zagayevskiy, Y., Amini, S., &amp; Madasu, S. (2021). An integrated closed-loop solution to assisted history matching and field optimization with machine learning techniques. Journal of Petroleum Science and Engineering, 198, 108204.
- Bukhamsin, A. Y., Farshi, M. M., &amp; Aziz, K. (2010, January). Optimization of multilateral well design and location in a real field using a continuous genetic algorithm. In SPE/DGS Saudi Arabia Section Technical Symposium and Exhibition. Society of Petroleum Engineers.

---


## BayesOpt Applied to Reservoir Case:
BayesOpt VS. with other Global Optimization Algorithms

--
- Fixed Reservoir Simulation Budget (N=50)
&lt;img src="presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-25-1.png" width="1008" style="display: block; margin: auto;" /&gt;
--

---

## BayesOpt Applied to Reservoir Case:
BayesOpt VS. with other Global Optimization Algorithms

--

- Fixed Reservoir Simulation Budget (N=50)
- BO: Reservoir Simulation Budget (N=50), GA, PSO: Reservoir Simulation Budget (N=250)
&lt;img src="presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-26-1.png" width="864" style="display: block; margin: auto;" /&gt;
--
---

## BayesOpt Applied to Reservoir Case:
BayesOpt VS. with other Global Optimization Algorithms

--

.pull-left[
- Table Summarizing Comparison of BayesOpt, PSO, GA 

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Optimization Method &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Maximum Achieved NPV (median) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt;   # of `\(\overline{J}(u)\)` Evaluations &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Bayesian Optimization &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 36.848 &lt;/td&gt;
   &lt;td style="text-align:center;background-color: blue !important;"&gt; 50 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Particle Swarm Optimization &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 36.894 &lt;/td&gt;
   &lt;td style="text-align:center;background-color: blue !important;"&gt; 250 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Genetic Alghorithm Optimization &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 36.429 &lt;/td&gt;
   &lt;td style="text-align:center;background-color: blue !important;"&gt; 250 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

--

.pull-right[
- Comparing the Final Solution `\(u\)` of the Opt algorithms...(the Median Replication was used)

&lt;img src="presentation_DIGIRES_30June2021_files/figure-html/unnamed-chunk-28-1.png" width="504" style="display: block; margin: auto;" /&gt;
]

---

## Overview of BayesOpt in Reservoir Optimization

--

### Advantages

--

- The optimization algorithm scale up properly to the time consuming forward simulation. 

--

- The algorithm also is capable of a larger number of realizations, as they are embedded in calculating `\(\overline{J}(u)\)` 

--

- The Bayesopt in essence visits all local optimum points, therefore is capable of converging toward the global optimum.

--

### Downsides

--

- Getting the covariance function model wrong can be catastrophic.

--
- `$$\text{log} p(y|\bf{X,\theta})=\mathcal{L}(\zeta,\sigma_f^2)=-\frac{1}{2}(y-\mu_X)^{\intercal}\color{red}{\mathbf{K}_{X,X}^{-1}}(y-\mu_X)-\frac{1}{2}log|K_{X,X}|-\frac{n}{2}log(2\pi)$$`
- The inversion of `\(K_{X,X}^{-1}\)` takes `\(O(N^3)\)` and then `\(O(N^2)\)` time per hyper-parameter to compute the gradient. Therefore, BayesOpt does not scale properly with #of initial design points, `\(N\)`&lt;1000.

--
---


&lt;!-- - Suppose we have a initial design points, set `\(\mathcal{D} = {(x_n, y_n) : n = 1 : N}\)`, where `\(y_n = f(x_n)\)` is the noise-free observation of the function evaluated at `\(x\)`. --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- - Now we consider the case of predicting the outputs for new inputs that may not be in `\(\mathcal{D}\)`. Specifically, given a test set `\(X_‚àó\)` of size `\(N_‚àó √ó D\)`, we want to predict the function outputs `\(\bf{f_‚àó} = [f(x_1), . . . , f(x_{N_*})]\)`. --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;

&lt;!-- ## Step 1. Probalistic Model as Prior --&gt;
&lt;!-- ### Gaussian Process (GP), (cont)  --&gt;
&lt;!-- - By definition of the GP, the joint distribution `\(p(\bf{f_X,f_‚àó|X, X_‚àó})\)` has the following form: --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- $$\begin{bmatrix}  {\bf {f}_X}  \\  {{\bf f}_*} \end{bmatrix} \sim\mathcal{N} \begin{pmatrix} (\begin{bmatrix}  {{\bf \mu}_X}  \\  {{\bf \mu}_*} \end{bmatrix}),\begin{bmatrix} {{\bf K}_{X,X}}  &amp; {{\bf --&gt;
&lt;!-- K}_{X,*}}  \\  {{\bf \mathbf{K}^\intercal}_{X,*}} &amp; {{\bf K}_{*,*} } \end{bmatrix}\end{pmatrix}$$ --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- &lt;br/&gt; --&gt;
&lt;!-- &lt;br/&gt; --&gt;
&lt;!-- - `\(\mu_X = [m(x_1),...,m(x_N)], \; \; \; \mu^* = [m(x^*_1,...m(x^*_N))]\)` --&gt;
&lt;!-- - `\(K_{X,X} = {\Large \kappa} (X,X; \theta) , \; \; \; \; \; \ size (N √ó N)\)`  --&gt;
&lt;!-- - `\(K_{X,*} = {\Large \kappa} (X,X_*; \theta), \; \; \; \; \; \ size (N √ó N_*)\)`  --&gt;
&lt;!-- - `\(K_{*,*} = {\Large \kappa}(X_*, X_‚àó; \theta), \; \; \; \; \; \ size(N_*√óN_*)\)` --&gt;
&lt;!-- -- --&gt;
&lt;!-- --- --&gt;
&lt;!-- ## Step 1. Probalistic Model as Prior  --&gt;
&lt;!-- ### Covariance Kernel --&gt;
&lt;!-- ### Covariance Kernels --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- ```{r, echo=FALSE} --&gt;
&lt;!-- df &lt;- data.frame(key = c("Gaussain",  --&gt;
&lt;!--                          "Matern `\(\\mu=\\frac{5}{2}\)`",  --&gt;
&lt;!--                          "Matern `\(\\mu=\\frac{3}{2}\)`", --&gt;
&lt;!--                          "Exponetial", --&gt;
&lt;!--                          "Power-Exponetial"),  --&gt;
&lt;!--                  equation = c("$\\Large \\kappa (x,x') =\\sigma_f^2 exp(-\\frac{h^2}{2\\ell^2})$", --&gt;
&lt;!-- "$\\Large \\kappa (x,x') =\\sigma_f^2(1 + \\frac{\\sqrt{5}|h|}{\\ell}\\frac{5h^2}{3\\ell^2})exp(-\\frac{ -\\sqrt{5}|h|}{\\ell})$", --&gt;
&lt;!-- "$\\Large \\kappa (x,x') =\\sigma_f^2(1 + \\frac{\\sqrt{3}|h|}{\\ell})exp(-\\frac{-\\sqrt{3}|h|}{\\ell})$", --&gt;
&lt;!-- "$\\Large \\kappa (x,x') =\\sigma_f^2 exp(-\\frac{|h|}{\\ell})$", --&gt;
&lt;!-- "$\\Large \\kappa (x,x') =\\sigma_f^2 exp(-(\\frac{|h|}{\\ell})^p)$" --&gt;
&lt;!-- )) --&gt;

&lt;!-- colnames(df) &lt;- c("Covariance Kernels","assumeing `\(h=||x-x'||\)`") --&gt;
&lt;!-- #df %&gt;%  knitr::kable(format = "html", escape = FALSE ) --&gt;
&lt;!-- df %&gt;%  kableExtra::kable(format = "html", escape = FALSE) %&gt;%  --&gt;
&lt;!--     kable_styling() %&gt;%  --&gt;
&lt;!--   row_spec(2, background = "green") --&gt;

&lt;!-- ``` --&gt;
&lt;!-- -- --&gt;
&lt;!-- - In this work: --&gt;
&lt;!-- $${\Large \kappa} (x,x';\theta) =(1 + \frac{\sqrt{5}|h|}{\theta} + \frac{5h^2}{3\theta^2})exp(-\frac{ --&gt;
&lt;!-- -\sqrt{5}|h|}{\theta})$$ --&gt;
&lt;!-- --- --&gt;
&lt;!-- ## Step 1. Probalistic Model as Prior  --&gt;
&lt;!-- ### Covariance Kernel, Parameter estimation --&gt;
&lt;!-- -- --&gt;


&lt;!-- `$$p(y|\bf{X,\theta}) = \int p(y|\bf{f,X})p(f|\bf{X,\theta})$$` --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;

&lt;!-- `$$\text{log} p(y|\bf{X,\theta})=\mathcal{L}(\zeta,\sigma_f^2)=-\frac{1}{2}(y-\mu_X)^{\intercal}\mathbf{K}_{X,X}^{-1}(y-\mu_X)-\frac{1}{2}log|K_{X,X}|-\frac{n}{2}log(2\pi)$$` --&gt;
&lt;!-- -- --&gt;
&lt;!-- - Where the dependence of the `\(\bf{K}_{X,X}\)` on `\(\theta\)` is implicit. --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- - The gradient-based optimizer is performed in order to: --&gt;

&lt;!-- `$$[\zeta^*, \sigma_f^{2*}]=argmax\mathcal{L}(\zeta,\sigma^2_f)$$` --&gt;
&lt;!-- {{content}} --&gt;
&lt;!-- -- --&gt;
&lt;!-- - However, since the objective `\(\mathcal{L}\)` is not convex, local minima can be a problem, so we may need to use multiple restarts. --&gt;
&lt;!-- --- --&gt;
&lt;!-- ## Step 2. Posterior of Probabilistic Model --&gt;
&lt;!-- ### Posterior of Gaussain Process, (conditioning on initial data) --&gt;
&lt;!-- -- --&gt;
&lt;!-- ```{r, echo=FALSE, fig.align='center', out.width="500px", out.height="200px", fig.retina=4} --&gt;
&lt;!-- knitr::include_graphics("gaus_norm.png") --&gt;
&lt;!-- ``` --&gt;
&lt;!-- -- --&gt;

&lt;!-- `$$p(f_*|X_*,\mathcal{D}) = \mathcal{N}(f_*|{{\bf \mu}_*} , \scriptsize{\sum}_{*}\normalsize)=$$` --&gt;
&lt;!-- `$${{\bf \mu}_*}=m(\bf X_*) +{\bf \mathbf{K}^\intercal}_{X,*}{\bf \mathbf{K}^{-1}}_{X,X}(f_X-m(X))$$` --&gt;
&lt;!-- `$$\scriptsize{\sum}_{*}= \normalsize{\mathbf{K}_{*,*}-\mathbf{K}^\intercal_{X,*}\mathbf{K}_{X,X}^{-1}\mathbf{K}_{X,*}}$$` --&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
(function(time) {
  var d2 = function(number) {
    return ('0' + number).slice(-2); // left-pad 0 to minutes/seconds
  },

  time_format = function(total) {
    var secs = Math.abs(total) / 1000;
    var h = Math.floor(secs / 3600);
    var m = Math.floor(secs % 3600 / 60);
    var s = Math.round(secs % 60);
    var res = d2(m) + ':' + d2(s);
    if (h > 0) res = h + ':' + res;
    return res;  // [hh:]mm:ss
  },

  slide_number_div = function(i) {
    return document.getElementsByClassName('remark-slide-number').item(i);
  },

  current_page_number = function(i) {
    return slide_number_div(i).firstChild.textContent;  // text "i / N"
  };

  var timer = document.createElement('span'); timer.id = 'slide-time-left';
  var time_left = time, k = slideshow.getCurrentSlideIndex(),
      last_page_number = current_page_number(k);

  setInterval(function() {
    time_left = time_left - 1000;
    timer.innerHTML = ' ' + time_format(time_left);
    if (time_left < 0) timer.style.color = 'red';
  }, 1000);

  slide_number_div(k).appendChild(timer);

  slideshow.on('showSlide', function(slide) {
    var i = slide.getSlideIndex(), n = current_page_number(i);
    // reset timer when a new slide is shown and the page number is changed
    if (last_page_number !== n) {
      time_left = time; last_page_number = n;
      timer.innerHTML = ' ' + time_format(time); timer.style.color = null;
    }
    slide_number_div(i).appendChild(timer);
  });
})(60000);
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
